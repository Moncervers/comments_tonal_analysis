# Классификация токсичных комментариев

Этот проект посвящён созданию модели машинного обучения для классификации токсичных комментариев в интернет-магазине, где пользователи могут редактировать и комментировать описания товаров в стиле вики-сообщества. Цель проекта — автоматизировать модерацию, выявляя токсичные комментарии (например, содержащие оскорбления или вредоносный контент) и отправляя их на проверку. В проекте сравниваются два подхода к извлечению признаков: векторизация с помощью TF-IDF и эмбеддинги BERT, чтобы показать их влияние на производительность модели.

Этот проект демонстрирует ключевые навыки в обработке естественного языка (NLP), машинном обучении, анализе данных и оценке моделей. Он подчёркивает умение работать с несбалансированными данными, предобработкой текста, генерацией эмбеддингов, настройкой гиперпараметров и оценкой производительности с помощью метрики F1.

Используемые библиотеки: Pandas, NumPy, re, NLTK, transformers, Scikit-Learn, LightGBM.

## Содержание
- [Описание проекта](#описание-проекта)
- [Датасет](#датасет)
- [Предобработка данных](#предобработка-данных)
- [Исследовательский анализ данных (EDA)](#исследовательский-анализ-данных-eda)
- [Извлечение признаков](#извлечение-признаков)
- [Моделирование](#моделирование)
- [Результаты](#результаты)
- [Выводы и рекомендации](#выводы-и-рекомендации)
- [Будущие улучшения](#будущие-улучшения)

## Описание проекта
Интернет-магазин запускает сервис, позволяющий пользователям редактировать описания товаров и комментировать правки других, как в вики-сообществах. Для поддержания позитивной среды необходимо выявлять токсичные комментарии и отправлять их на модерацию. Проект направлен на обучение моделей бинарной классификации для разметки комментариев как токсичных (1) или нетоксичных (0), с целевой метрикой F1 не менее 0.75 на тестовой выборке.

Основные цели:
- Предобработка и анализ текстовых данных.
- Сравнение традиционного (TF-IDF) и продвинутого (BERT) подходов к извлечению признаков.
- Обучение и оценка моделей, таких как логистическая регрессия и LightGBM.
- Формулировка рекомендаций для интеграции в продакшн.

Проект состоит из двух Jupyter-ноутбуков:
- `analysis_using_TFIDF.ipynb`: Использует TF-IDF для векторизации.
- `analysis_using_BERT.ipynb`: Использует BERT для генерации эмбеддингов.

## Датасет
Датасет содержит ~159,000 комментариев на английском языке с вики-платформы:
- **Столбцы**:
  - `text`: Текст комментария (строка).
  - `toxic`: Целевая метка (1 — токсичный, 0 — нетоксичный; int8 для экономии памяти).
- **Характеристики**:
  - Сильный дисбаланс классов: ~10% токсичных комментариев.
  - Длина текста: Большинство комментариев короче 1000 символов, с выбросами до 5000 (часто повторяющиеся фразы).
- Источник: CSV-файл (`toxic_comments.csv`).
- Пропуски отсутствуют; дубликаты проверены и обработаны.

## Предобработка данных
- Удалён ненужный столбец индекса (`Unnamed: 0`).
- Текст приведён к формату Unicode (UTF) для совместимости с NLP-инструментами.
- Проведена очистка текста с помощью регулярных выражений: удалены неалфавитные символы, текст приведён к нижнему регистру, обработаны сокращения и переносы строк.
- Данные разделены на обучающую и тестовую выборки (80/20) с сохранением баланса классов через стратификацию.

## Исследовательский анализ данных (EDA)
- **Распределение классов**: Визуализировано с помощью столбчатых диаграмм — подтверждён дисбаланс (~90% нетоксичных vs ~10% токсичных).
- **Анализ длины текста**: Гистограммы и боксплоты показали, что большинство текстов короткие; выбросы проанализированы, но сохранены, так как отражают реальные шаблоны спама/токсичности.
- **Частота слов**: В TF-IDF-ноутбуке проанализированы топ-слова в токсичных/нетоксичных классах (например, оскорбления вроде "idiot" доминируют в токсичных текстах).
- Визуализации: Matplotlib и Seaborn для построения графиков.

EDA помог принять решения по извлечению признаков, акцентируя внимание на семантических эмбеддингах для лучшего выявления токсичности.

## Извлечение признаков
Рассмотрены два подхода к векторизации текста:

1. **Векторизация TF-IDF** (`analysis_using_TFIDF.ipynb`):
   - Токенизация и лемматизация текста с использованием WordNetLemmatizer из NLTK.
   - Удалены стоп-слова.
   - Применён TfidfVectorizer для создания разреженных матриц признаков.
   - Плюсы: Быстро и легковесно.
   - Минусы: Ограничивается частотой слов; не улавливает контекст/семантику.

2. **Эмбеддинги BERT** (`analysis_using_BERT.ipynb`):
   - Использована предобученная модель `toxic-bert` из Hugging Face Transformers.
   - Токенизация текстов с помощью BERT Tokenizer (максимальная длина 512, с обрезкой).
   - Генерация эмбеддингов пакетами (для обработки большого датасета) с использованием GPU/CPU
   - Извлечены эмбеддинги токена [CLS] (768-мерные векторы) для классификации.
   - Плюсы: Захватывает глубокую семантику и контекст.
   - Минусы: Высокая вычислительная сложность (ускорено с помощью MPS/GPU).

Эмбеддинги BERT значительно улучшили производительность благодаря лучшему представлению нюансов токсичности.

## Моделирование
- **Обученные модели**:
  - **Логистическая регрессия**: Базовая линейная модель (быстрая, интерпретируемая).
  - **LightGBM**: Градиентный бустинг для обработки нелинейностей и дисбаланса.
- **Настройка гиперпараметров**: RandomizedSearchCV с 5-кратной кросс-валидацией.
- **Метрика оценки**: F1-score
- **Дополнительно**: Построены матрицы ошибок для анализа (ложные срабатывания/пропуски).

## Результаты
Оба подхода достигли порога F1 >= 0.75, но BERT значительно превзошёл TF-IDF.

| Подход | Модель                  | F1 на тесте | Время обучения                | Примечания                                            |
|--------|-------------------------|-------------|-------------------------------|-------------------------------------------------------|
| TF-IDF | Логистическая регрессия | 0.78        | ~2 минуты                     | Хороший базовый уровень; немного ложных срабатываний. |
| TF-IDF | LightGBM                | 0.78        | ~10 минут                     | Аналогично LR, но медленнее.                          |
| BERT   | Логистическая регрессия | 0.93        | ~2 минуты (после эмбеддингов) | Отлично; низкий уровень ошибок (260 FP, 340 FN).      |
| BERT   | LightGBM                | 0.92        | ~5 минут                      | Чуть ниже LR, но надёжно.                             |

- **Матрицы ошибок**: Визуализированы в ноутбуках — BERT эффективно сократил ложные отрицательные результаты (пропущенные токсичные комментарии).
- Превосходство BERT в F1 подчёркивает ценность контекстных эмбеддингов для задач NLP.

## Выводы и рекомендации
- **Основные выводы**: Эмбеддинги BERT обеспечили ~15% прирост F1 по сравнению с TF-IDF, демонстрируя важность семантического анализа для выявления токсичности. Логистическая регрессия оказалась наиболее эффективной по времени и метрике.
- **Бизнес-эффект**: Модель может сократить ручную модерацию на 90%+, флаггируя токсичные комментарии в реальном времени.
- **Рекомендации**: Добавить историю пользователя (например, количество прошлых токсичных постов) как дополнительный признак.
- Проект укрепил навыки в создании NLP-пайплайнов, сравнении моделей и этических аспектах ИИ.


## Будущие улучшения
- Эксперименты с тонкой настройкой BERT для классификации (вместо эмбеддингов + ML).
- Добавление поддержки многоязычных комментариев.
- Использование ансамблевых методов (например, комбинация TF-IDF и BERT-признаков).
- Тестирование на сложных случаях, таких как сарказм или скрытая токсичность.
